{"cells":[{"source":"![wordcloud](wordcloud.png)\n\nAs a Data Scientist working for a mobile app company, you usually find yourself applying product analytics to better understand user behavior, uncover patterns, and reveal insights to identify the great and not-so-great features. Recently, the number of negative reviews has increased on Google Play, and as a consequence, the app's rating has been decreasing. The team has requested you to analyze the situation and make sense of the negative reviews.\n\nIt's up to you to apply K-means clustering from scikit-learn and NLP techniques through NLTK to sort text data from negative reviews in the Google Play Store into categories!\n\n## The Data\n\nA dataset has been shared with a sample of reviews and their respective scores (from 1 to 5) in the Google Play Store. A summary and preview are provided below.\n\n# reviews.csv\n\n| Column     | Description              |\n|------------|--------------------------|\n| `'content'` | Content (text) of each review. |\n| `'score'` | Score assigned to the review by the user as an integer (from 1 to 5). |","metadata":{},"id":"c79a760b-d438-41bb-b1a1-2578773c0fe0","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1725239521381,"lastExecutedByKernel":"4d6c600f-7bdb-4015-b782-824979e4b533","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize"},"id":"48172b7a-d771-435b-a6fe-c99134ac5eba","cell_type":"code","execution_count":7,"outputs":[]},{"source":"# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1725239521429,"lastExecutedByKernel":"4d6c600f-7bdb-4015-b782-824979e4b533","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"8a6577b0-9915-43c7-b1db-b0c106a71cca","cell_type":"code","execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":8}]},{"source":"# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1725239521477,"lastExecutedByKernel":"4d6c600f-7bdb-4015-b782-824979e4b533","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()","outputsMetadata":{"0":{"height":231,"type":"dataFrame"}}},"id":"7fbf3e3f-0526-4f53-908e-0bf9913f213d","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"content","type":"string"},{"name":"score","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"content":["I cannot open the app anymore","I have been begging for a refund from this app for over a month and nobody is replying me","Very costly for the premium version (approx Indian Rupees 910 per year). Better to download the premium version of this app from apkmos website and use it. Microsoft to do list app is far more better.","Used to keep me organized, but all the 2020 UPDATES have made a mess of things !!! Y cudn't u leave well enuf alone ??? Guess ur techies feel the need to keep making changes to justify continuing to collect their salary !!! ðŸ¤¤ðŸ¤¤ðŸ¤¤","Dan Birthday Oct 28"],"score":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"                                             content  score\n0                      I cannot open the app anymore      1\n1  I have been begging for a refund from this app...      1\n2  Very costly for the premium version (approx In...      1\n3  Used to keep me organized, but all the 2020 UP...      1\n4                                Dan Birthday Oct 28      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I cannot open the app anymore</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I have been begging for a refund from this app...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Very costly for the premium version (approx In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Used to keep me organized, but all the 2020 UP...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dan Birthday Oct 28</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":9}]},{"source":"# Your code starts here\n\n# Step 1: Preprocess the negative reviews\n# Filter negative reviews (having a score of 1 or 2)\nnegative_reviews_tmp = reviews[(reviews[\"score\"] == 1) | (reviews[\"score\"] == 2)][\"content\"]\ndef preprocess_text(text):\n    \"\"\"Performs all the required steps in the text preprocessing\"\"\"\n    # Tokenizing the text\n    tokens = word_tokenize(text)\n    # Removing stop words and non-alpha characters\n    filtered_tokens = [\n        token\n        for token in tokens\n        if token.isalpha() and token.lower() not in stopwords.words(\"english\")\n    ]\n    return \" \".join(filtered_tokens)\n# Apply the preprocessing function to the negative reviews\nnegative_reviews_cleaned = negative_reviews_tmp.apply(preprocess_text)\n# Store the preprocessed negative reviews in a pandas DataFrame\npreprocessed_reviews = pd.DataFrame({\"review\": negative_reviews_cleaned})\npreprocessed_reviews.head()\n\n# Step 2: Vectorize the cleaned negative reviews using TF-IDF\n# Vectorize the cleaned reviews using TF-IDF\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"review\"])\n\n# Step 3: Apply K-means clustering to tfidf_matrix\n# Apply K-means clustering (store the model as clust_kmeans)\nclust_kmeans = KMeans(n_clusters=5, random_state=500)\npred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n# Store the predicted labels in a list variable called categories\ncategories = pred_labels.tolist()\npreprocessed_reviews[\"category\"] = categories\n\n# Step 4: For each unique cluster label, find the most frequent term\n# Get the feature names (terms) from the vectorizer\nterms = vectorizer.get_feature_names_out()\n# List to save the top term for each cluster\ntopic_terms_list = []\nfor cluster in range(clust_kmeans.n_clusters):\n    # Get indices of reviews in the current cluster\n    cluster_indices = [i for i, label in enumerate(categories) if label == cluster]\n    # Sum the tf-idf scores for each term in the cluster\n    cluster_tfidf_sum = tfidf_matrix[cluster_indices].sum(axis=0)\n    cluster_term_freq = np.asarray(cluster_tfidf_sum).ravel()\n    # Get the top term and its frequencies\n    top_term_index = cluster_term_freq.argsort()[::-1][0]\n    # Append rows to the topic_terms DataFrame with three fields:\n    # - category: label / cluster assigned from K-means\n    # - term: the identified top term\n    # - frequency: term's weight for the category\n    topic_terms_list.append(\n        {\n            \"category\": cluster,\n            \"term\": terms[top_term_index],\n            \"frequency\": cluster_term_freq[top_term_index],\n        }\n    )\n\n# Pandas DataFrame to store results from this step\ntopic_terms = pd.DataFrame(topic_terms_list)\n# Output the final result\nprint(topic_terms)\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":143,"type":"stream"}}},"id":"3b2697f7-e85a-4a11-bfbb-59af07b89c75","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"   category      term   frequency\n0         0       app  186.525216\n1         1   version   63.738669\n2         2      good   52.935519\n3         3   premium   55.750426\n4         4  calendar   70.971649\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}